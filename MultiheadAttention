{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPfKq9nJ6Ts1k0gpXs8hYKn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from matplotlib_inline import backend_inline\n","from matplotlib import pyplot as plt\n","from IPython import get_ipython\n","from IPython import display\n","import torch\n","import random\n","import re\n","import collections\n","import inspect\n","import os\n","import hashlib # Added missing import\n","import zipfile # Added missing import\n","import tarfile # Added missing import\n","import requests # Import the requests library\n","from torch import nn\n","from torch.nn import functional as F"],"metadata":{"id":"MPIRm_Oi8ljo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def use_svg_display():\n","    \"\"\"Use the svg format to display a plot in Jupyter.\n","\n","    Defined in :numref:`sec_calculus`\"\"\"\n","    backend_inline.set_matplotlib_formats('svg')\n","def set_figsize(figsize=(3.5,2.5)):\n","    use_svg_display()\n","    plt.rcParams['figure.figsize']=figsize\n","def set_axes(axes,xlabel,ylabel,xlim,ylim,xscale,yscale,legend):\n","    axes.set_xlabel(xlabel), axes.set_ylabel(ylabel)\n","    axes.set_xscale(xscale), axes.set_yscale(yscale)\n","    axes.set_xlim(xlim), axes.set_ylim(ylim)\n","    if legend:\n","        axes.legend(legend)\n","    axes.grid()\n","def plot(X,Y=None,xlabel=None, ylabel=None, legend=[],xlim=None, ylim=None, xscale='linear',yscale='linear',fmts=('-','m--','g-.','r:'),figsize=(3.5,2.5),axes=None):\n","    def has_one_axis(X):\n","        return(hasattr(X,'ndim') and X.ndim == 1 or isinstance(X,list) and not hasattr(X[0],\"__len__\"))\n","    if has_one_axis(X): X=[X]\n","    if Y is None:\n","        X,Y=[[]]*len(X),X\n","    elif has_one_axis(Y):\n","        Y=[Y]\n","    if len(X) != len(Y):\n","        X=X*len(Y)\n","    set_figsize(figsize)\n","    if axes is None:\n","        axes=plt.gca()\n","    axes.cla()\n","    for x,y,fmt in zip (X,Y,fmts):\n","        axes.plot(x,y,fmt) if len(x) else axes.plot(y,fmt)\n","    set_axes(axes,xlabel,ylabel,xlim,ylim,xscale,yscale,legend)\n","\n","class HyperParameters:\n","    \"\"\"The base class of hyperparameters.\"\"\"\n","    def save_hyperparameters(self, ignore=[]):\n","        \"\"\"Defined in :numref:`sec_oo-design`\"\"\"\n","        raise NotImplemented\n","\n","    def save_hyperparameters(self, ignore=[]):\n","        \"\"\"Save function arguments into class attributes.\n","\n","        Defined in :numref:`sec_utils`\"\"\"\n","        frame = inspect.currentframe().f_back\n","        _, _, _, local_vars = inspect.getargvalues(frame)\n","        self.hparams = {k:v for k, v in local_vars.items()\n","                        if k not in set(ignore+['self']) and not k.startswith('_')}\n","        for k, v in self.hparams.items():\n","            setattr(self, k, v)\n","\n","class ProgressBoard(HyperParameters):\n","    \"\"\"The board that plots data points in animation.\n","\n","    Defined in :numref:`sec_oo-design`\"\"\"\n","    def __init__(self, xlabel=None, ylabel=None, xlim=None,\n","                 ylim=None, xscale='linear', yscale='linear',\n","                 ls=['-', '--', '-.', ':'], colors=['C0', 'C1', 'C2', 'C3'],\n","                 fig=None, axes=None, figsize=(3.5, 2.5), display=True):\n","        self.save_hyperparameters()\n","\n","    def draw(self, x, y, label, every_n=1):\n","        raise NotImplemented\n","\n","    def draw(self, x, y, label, every_n=1):\n","        \"\"\"Defined in :numref:`sec_utils`\"\"\"\n","        Point = collections.namedtuple('Point', ['x', 'y'])\n","        if not hasattr(self, 'raw_points'):\n","            self.raw_points = collections.OrderedDict()\n","            self.data = collections.OrderedDict()\n","        if label not in self.raw_points:\n","            self.raw_points[label] = []\n","            self.data[label] = []\n","        points = self.raw_points[label]\n","        line = self.data[label]\n","        points.append(Point(x, y))\n","        if len(points) != every_n:\n","            return\n","        mean = lambda x: sum(x) / len(x)\n","        line.append(Point(mean([p.x for p in points]),\n","                          mean([p.y for p in points])))\n","        points.clear()\n","        if not self.display:\n","            return\n","        use_svg_display()\n","        if self.fig is None:\n","            self.fig = plt.figure(figsize=self.figsize)\n","        plt_lines, labels = [], []\n","        for (k, v), ls, color in zip(self.data.items(), self.ls, self.colors):\n","            plt_lines.append(plt.plot([p.x for p in v], [p.y for p in v],\n","                                          linestyle=ls, color=color)[0])\n","            labels.append(k)\n","        axes = self.axes if self.axes else plt.gca()\n","        if self.xlim: axes.set_xlim(self.xlim)\n","        if self.ylim: axes.set_ylim(self.ylim)\n","        if not self.xlabel: self.xlabel = self.x\n","        axes.set_xlabel(self.xlabel)\n","        axes.set_ylabel(self.ylabel)\n","        axes.set_xscale(self.xscale)\n","        axes.set_yscale(self.yscale)\n","        axes.legend(plt_lines, labels)\n","        display.display(self.fig)\n","        display.clear_output(wait=True)\n"],"metadata":{"id":"8GmBXFpg9P5O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Module(nn.Module, HyperParameters):\n","    def __init__(self,plot_train_per_epoch=2, plot_valid_per_epoch=1):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.board= ProgressBoard()\n","    def squared_loss(self,y_hat,y):\n","        return(y_hat-y.reshape(y_hat.shape))**2/2\n","    def forward(self, X):\n","        assert hasattr(self, 'net'), 'Neural Network is defined'\n","        return self.net(X)\n","    def plot(self, key, value, train):\n","        assert hasattr(self,'trainer'), 'Trainer is not inited'\n","        self.board.xlabel='epoch'\n","        if train:\n","            x= self.trainer.train_batch_idx / \\\n","                self.trainer.num_train_batches\n","            n=self.trainer.num_train_batches / \\\n","                self.plot_train_per_epoch\n","        else:\n","            x=self.trainer.epoch+1\n","            n=self.trainer.num_val_batches / \\\n","                self.plot_valid_per_epoch\n","        if isinstance(value, int):\n","            value=torch.tensor(value)\n","        self.board.draw(x,value.to('cpu').detach().numpy(), ('train_' if train else 'val_')+key, every_n=int(n))\n","\n","    def training_step(self, batch):\n","        l=self.loss(self(*batch[:-1]), batch[-1])\n","        self.plot('loss', l, train=True)\n","        return l\n","    def validation_step(self,batch):\n","        l=self.loss(self(*batch[:-1]), batch[-1])\n","        self.plot('loss', l, train=False)\n","    def configure_optimizers(self):\n","        return torch.optim.SGD(self.parameters(),lr=self.lr)\n","    def  apply_init(self, inputs, init=None):\n","        self.forward(inputs)\n","        if init is not None:\n","            self.net.apply(init)"],"metadata":{"id":"FiKOFkVk9JfV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DataModule(HyperParameters):\n","    def __init__(self, root='./data', num_workers=4):\n","        self.save_hyperparameters()\n","    def get_dataloader(self,train):\n","        i=slice(0,self.num_train) if train else slice(self.num_train, None)\n","        return self.get_tensorloader((self.X, self.y), train, i)\n","    def train_dataloader(self):\n","        return self.get_dataloader(train=True)\n","    def val_dataloader(self):\n","        return self.get_dataloader(train=False)\n","    def get_tensorloader(self, tensors, train, indices=slice(0, None)):\n","        tensors = tuple(a[indices] for a in tensors)\n","        dataset = torch.utils.data.TensorDataset(*tensors)\n","        return torch.utils.data.DataLoader(dataset, self.batch_size, shuffle=train)\n"],"metadata":{"id":"mYec5ZP09pgm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gpu(i=0):\n","    return torch.device(f'cuda:{i}')\n","def num_gpus():\n","    return torch.cuda.device_count()\n","class Trainer(HyperParameters):\n","    def __init__(self, max_epochs, num_gpus_arg=0, gradient_clip_val=0):\n","        self.save_hyperparameters()\n","        self.gpus=[gpu(i) for i in range(min(num_gpus_arg, num_gpus()))]\n","    def prepare_data(self,data):\n","        self.train_dataloader=data.train_dataloader()\n","        self.val_dataloader=data.val_dataloader()\n","        self.num_train_batches=len(self.train_dataloader)\n","        self.num_val_batches=(len(self.val_dataloader) if self.val_dataloader is not None else 0)\n","    def prepare_model(self,model):\n","        model.trainer=self\n","        model.board.xlim=[0,self.max_epochs]\n","        if self.gpus:\n","            model.to(self.gpus[0])\n","        self.model=model\n","    def fit(self,model,data):\n","        self.prepare_data(data)\n","        self.prepare_model(model)\n","        self.optim=model.configure_optimizers()\n","        self.epoch=0\n","        self.train_batch_idx=0\n","        self.val_batch_idx=0\n","        for self.epoch in range(self.max_epochs):\n","            self.fit_epoch()\n","    def fit_epoch(self):\n","        self.model.train()\n","        for batch in self.train_dataloader:\n","            loss = self.model.training_step(self.prepare_batch(batch))\n","            self.optim.zero_grad()\n","            with torch.no_grad():\n","                loss.backward()\n","                if self.gradient_clip_val > 0: # To be discussed later\n","                    self.clip_gradients(self.gradient_clip_val, self.model)\n","                self.optim.step()\n","            self.train_batch_idx += 1\n","        if self.val_dataloader is None:\n","            return\n","        self.model.eval()\n","        for batch in self.val_dataloader:\n","            with torch.no_grad():\n","                self.model.validation_step(self.prepare_batch(batch))\n","            self.val_batch_idx += 1\n","    def prepare_batch(self,batch):\n","        if self.gpus:\n","            batch=[a.to(self.gpus[0]) for a in batch]\n","        return batch\n","    def clip_gradients(self, grad_clip_val, model):\n","        params = [p for p in model.parameters() if p.requires_grad]\n","        norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n","        if norm > grad_clip_val:\n","            for param in params:\n","                param.grad[:] *= grad_clip_val / norm\n","\n"],"metadata":{"id":"phu0SHYu9z9g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Classifier(Module):\n","    def validation_step(self, batch):\n","        Y_hat = self(*batch[:-1])\n","        self.plot('loss', self.loss(Y_hat, batch[-1]), train=False)\n","        self.plot('acc', self.accuracy(Y_hat, batch[-1]), train=False)\n","    def accuracy(Self, Y_hat, Y, averaged=True):\n","        Y_hat= Y_hat.reshape((-1, Y_hat.shape[-1]))\n","        preds=Y_hat.argmax(axis=1).type(Y.dtype)\n","        compare=(preds==Y.reshape(-1)).type(torch.float32)\n","        return compare.mean() if averaged else compare\n","    def layer_summary(self,X_shape):\n","        X=torch.randn(*X_shape)\n","        for layer in self.net:\n","            X=layer(X)\n","            print(layer.__class__.__name__, 'output shape: \\t', X.shape)"],"metadata":{"id":"LDekJ1vM-Tic"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def download(url, folder='../data', sha1_hash=None):\n","    \"\"\"Download a file to folder and return the local filepath.\"\"\"\n","    if not url.startswith('http'):\n","    # For back compatability\n","        url, sha1_hash = DATA_HUB[url]\n","    os.makedirs(folder, exist_ok=True)\n","    fname = os.path.join(folder, url.split('/')[-1])\n","    # Check if hit cache\n","    if os.path.exists(fname) and sha1_hash:\n","        sha1 = hashlib.sha1()\n","        with open(fname, 'rb') as f:\n","            while True:\n","                data = f.read(1048576)\n","                if not data:\n","                    break\n","            sha1.update(data)\n","        if sha1.hexdigest() == sha1_hash:\n","            return fname\n","    # Download\n","    print(f'Downloading {fname} from {url}...')\n","    r = requests.get(url, stream=True, verify=True)\n","    with open(fname, 'wb') as f:\n","        f.write(r.content)\n","    return fname\n","def extract(filename, folder=None):\n","    \"\"\"Extract a zip/tar file into folder.\"\"\"\n","    base_dir = os.path.dirname(filename)\n","    _, ext = os.path.splitext(filename)\n","    assert ext in ('.zip', '.tar', '.gz'), 'Only support zip/tar files.'\n","    if ext == '.zip':\n","        fp = zipfile.ZipFile(filename, 'r')\n","    else:\n","        fp = tarfile.open(filename, 'r')\n","    if folder is None:\n","        folder = base_dir\n","    fp.extractall(folder)"],"metadata":{"id":"9Jx-RXNgk9Zr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DATA_HUB = dict()\n","DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'"],"metadata":{"id":"K-UNZ4yUlChC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Vocab:\n","  def __init__(self, tokens=[], min_freq=0, reserved_tokens=[]):\n","    if tokens and isinstance(tokens[0],list):\n","      tokens=[token for line in tokens for token in line]\n","    counter=collections.Counter(tokens)\n","    self.token_freqs=sorted(counter.items(), key=lambda x:x[1], reverse=True)\n","    self.idx_to_token=list(sorted(set(['<unk>']+reserved_tokens+[token for token, freq in self.token_freqs if freq>=min_freq])))\n","    self.token_to_idx={token:idx for idx, token in enumerate(self.idx_to_token)}\n","  def __len__(self):\n","    return len(self.idx_to_token)\n","  def __getitem__(self,tokens):\n","    if not isinstance(tokens,(list,tuple)):\n","      return self.token_to_idx.get(tokens,self.unk)\n","    return [self.__getitem__(token) for token in tokens]\n","  def to_tokens(self, indices):\n","    if hasattr(indices,'__len__') and len(indices)>1:\n","      return [self.idx_to_token[int(index)] for index in indices]\n","    return self.idx_to_token[indices]\n","  @property\n","  def unk(self):\n","    return self.token_to_idx['<unk>']"],"metadata":{"id":"KpFscInsxJZC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MTFraEng(DataModule):\n","  def _download(self):\n","    extract(download(DATA_URL + 'fra-eng.zip', self.root, '94646ad1522d915e7b0f9296181140edcf86a4f5' ))\n","    with open(self.root+'/fra-eng/fra.txt', encoding='utf-8') as f:\n","      return f.read()\n","  def _preprocess(self, text):\n","    text=text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n","    no_space=lambda char, prev_char: char in ',.!?' and prev_char!=' '\n","    out=[' ' if i>0 and no_space(char, text[i-1]) else char for i,char in enumerate(text.lower())]\n","    return ''.join(out)\n","  def _tokenize(self, text, max_examples=None):\n","    src, tgt = [], []\n","    for i, line in enumerate(text.split('\\n')):\n","        if max_examples and i > max_examples:\n","            break\n","        parts=line.split('\\t')\n","        if len(parts)==2:\n","          src.append([t for t in f'{parts[0]}<eos>'.split(' ') if t])\n","          tgt.append([t for t in f'{parts[1]}<eos>'.split(' ') if t])\n","    return src, tgt\n","  def __init__(self, batch_size, num_steps=9, num_train=512, num_val=128):\n","    super(MTFraEng, self).__init__()\n","    self.save_hyperparameters()\n","    self.arrays, self.src_vocab, self.tgt_vocab = self._build_arrays(self._download())\n","  def _build_arrays(self, raw_text, src_vocab=None, tgt_vocab=None):\n","    def _build_array(sentences, vocab, is_tgt=False):\n","        pad_or_trim = lambda seq, t: (seq[:t] if len(seq) > t else seq + ['<pad>'] * (t - len(seq)))\n","        sentences = [pad_or_trim(s, self.num_steps) for s in sentences]\n","        if is_tgt:\n","            sentences = [['<bos>'] + s for s in sentences]\n","        if vocab is None:\n","            vocab = Vocab(sentences, min_freq=2)\n","        array = torch.tensor([vocab[s] for s in sentences])\n","        valid_len= (array!=vocab['<pad>']).type(torch.int32).sum(1)\n","        return array, vocab, valid_len\n","    src, tgt = self._tokenize(self._preprocess(raw_text), self.num_train + self.num_val)\n","    src_array, src_vocab, src_valid_len = _build_array(src, src_vocab)\n","    tgt_array, tgt_vocab, _ = _build_array(tgt, tgt_vocab, True)\n","    return ((src_array, tgt_array[:,:-1], src_valid_len, tgt_array[:,1:]), src_vocab, tgt_vocab)\n","  def get_dataloader(self, train):\n","    idx = slice(0, self.num_train) if train else slice(self.num_train, None)\n","    return self.get_tensorloader(self.arrays, train, idx)\n","  def build(self, src_sentences, tgt_sentences):\n","    raw_text='\\n'.join([src+'\\t'+ tgt for src, tgt in zip(src_sentences, tgt_sentences)])\n","    arrays, _, _ = self._build_arrays(raw_text, self.src_vocab, self.tgt_vocab)\n","    return arrays"],"metadata":{"id":"1uieO-stknzF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self):\n","      super().__init__()\n","    def forward(self, X, *args):\n","      raise NotImplemented\n","class Decoder(nn.Module):\n","    def __init__(self):\n","      super().__init__()\n","    def init_state(self, enc_outputs, *args):\n","      raise NotImplemented\n","    def forward(self, X, state):\n","      raise NotImplemented\n","class EncoderDecoder(Classifier):\n","  def __init__(self, encoder, decoder):\n","    super().__init__()\n","    self.encoder=encoder\n","    self.decoder=decoder\n","  def forward(self, enc_X, dec_X, *args):\n","    enc_all_outputs=self.encoder(enc_X, *args)\n","    dec_state = self.decoder.init_state(enc_all_outputs, *args)\n","    return self.decoder(dec_X, dec_state)[0]\n","  def predict_step(self, batch, device, num_steps, save_attention_weights=False):\n","    batch=[a.to(device) for a in batch]\n","    src, tgt, src_valid_len, _= batch\n","    self.encoder.to(device)\n","    self.decoder.to(device)\n","    enc_all_outputs=self.encoder(src, src_valid_len)\n","    dec_state=self.decoder.init_state(enc_all_outputs, src_valid_len)\n","    outputs, attention_weights = [tgt[:, (0)].unsqueeze(1)], []\n","    for _ in range(num_steps):\n","      Y, dec_state = self.decoder(outputs[-1], dec_state)\n","      outputs.append(Y.argmax(dim=2))\n","      if save_attention_weights:\n","        attention_weights.append(self.decoder.attention_weights)\n","    return torch.cat(outputs[1:], dim=1), attention_weights"],"metadata":{"id":"hYerWL4PoMFN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def init_seq2seq(module):\n","  if type(module)==nn.Linear:\n","    nn.init.xavier_uniform_(module.weight)\n","  if type(module) == nn.GRU:\n","    for param in module._flat_weights_names:\n","      if \"weight\" in param:\n","        nn.init.xavier_uniform_(module._parameters[param])"],"metadata":{"id":"99Ikj-M7wgZ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class RNN(Module):\n","  def __init__(self, num_inputs, num_hiddens):\n","    super().__init__()\n","    self.save_hyperparameters()\n","    self.rnn=nn.RNN(num_inputs, num_hiddens)\n","  def forward(self, inputs, H=None):\n","    return self.rnn(inputs, H)\n","class GRU(RNN):\n","  def __init__(self, num_inputs, num_hiddens, num_layers, dropout=0):\n","    Module.__init__(self)\n","    self.save_hyperparameters()\n","    self.rnn = nn.GRU(num_inputs, num_hiddens, num_layers,\n","    dropout=dropout)\n"],"metadata":{"id":"3UsY-u0SLZfu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def masked_softmax(X, valid_lens):\n","    def _sequence_mask(X, valid_len, value=0):\n","        maxlen = X.size(1)\n","        mask = torch.arange((maxlen), dtype=torch.float32,\n","                            device=X.device)[None, :] < valid_len[:, None]\n","        X[~mask] = value\n","        return X\n","    if valid_lens is None:\n","        return nn.functional.softmax(X, dim=-1)\n","    else:\n","        shape = X.shape\n","        if valid_lens.dim() == 1:\n","            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n","        else:\n","            valid_lens = valid_lens.reshape(-1)\n","        X = _sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)\n","        return nn.functional.softmax(X.reshape(shape), dim=-1)"],"metadata":{"id":"uPgqQXf5XLTI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5), cmap='Reds'):\n","    use_svg_display()\n","    num_rows, num_cols, _, _ =matrices.shape\n","    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize,\n","                             sharex=True, sharey=True, squeeze=False)\n","    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\n","        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\n","            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)\n","            if i == num_rows - 1:\n","                ax.set_xlabel(xlabel)\n","            if j == 0:\n","                ax.set_ylabel(ylabel)\n","            if titles:\n","                ax.set_title(titles[j])\n","    fig.colorbar(pcm, ax=axes, shrink=0.6);"],"metadata":{"id":"AWrkXT0Qi9cf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AdditiveAttention(nn.Module):\n","    def __init__(self, num_hiddens, dropout, **kwargs):\n","        super(AdditiveAttention, self).__init__(**kwargs)\n","        self.W_k = nn.LazyLinear(num_hiddens, bias=False)\n","        self.W_q = nn.LazyLinear(num_hiddens, bias=False)\n","        self.w_v = nn.LazyLinear(1, bias=False)\n","        self.dropout = nn.Dropout(dropout)\n","    def forward(self, queries, keys, values, valid_lens):\n","        queries, keys = self.W_q(queries), self.W_k(keys)\n","        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n","        features = torch.tanh(features)\n","        scores = self.w_v(features).squeeze(-1)\n","        self.attention_weights = masked_softmax(scores, valid_lens)\n","        return torch.bmm(self.dropout(self.attention_weights), values)\n"],"metadata":{"id":"u33rhNz9UJlM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DotProductAttention(nn.Module):\n","    def __init__(self, dropout):\n","        super().__init__()\n","        self.dropout = nn.Dropout(dropout)\n","    def forward(self, queries, keys, values, valid_lens=None):\n","        d = queries.shape[-1]\n","        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n","        self.attention_weights = masked_softmax(scores, valid_lens)\n","        return torch.bmm(self.dropout(self.attention_weights), values)"],"metadata":{"id":"wB6wvnEW0Dho"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Seq2SeqEncoder(Encoder):\n","  def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0):\n","    super().__init__()\n","    self.embedding=nn.Embedding(vocab_size, embed_size)\n","    self.rnn=GRU(embed_size, num_hiddens, num_layers, dropout)\n","    self.apply(init_seq2seq)\n","  def forward(self, X, *args):\n","    embs=self.embedding(X.t().type(torch.int64))\n","    outputs, state=self.rnn(embs)\n","    return outputs, state\n"],"metadata":{"id":"CEMIBxgJWK8u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Seq2Seq(EncoderDecoder):\n","  def __init__(self, encoder, decoder, tgt_pad, lr):\n","    super().__init__(encoder, decoder)\n","    self.save_hyperparameters()\n","  def validation_step(self, batch):\n","    Y_hat = self(*batch[:-1])\n","    self.plot('loss', self.loss(Y_hat, batch[-1]), train=False)\n","  def configure_optimizers(self):\n","    return torch.optim.Adam(self.parameters(), lr=self.lr)\n","  def loss(self, Y_hat, Y):\n","    Y_hat = Y_hat.reshape(-1, Y_hat.shape[-1])\n","    Y = Y.reshape(-1)\n","    l = F.cross_entropy(Y_hat, Y, reduction='none')\n","    mask = (Y.reshape(-1) != self.tgt_pad).type(torch.float32)\n","    return l.sum()/mask.sum()"],"metadata":{"id":"JaC82BELW4xs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AttentionDecoder(Decoder):\n","  def __init__(self):\n","    super().__init__()\n","  @property  # truy cap nhu bien ma khong can goi ham\n","  def attention_weights(self):\n","    raise NotImplementedError\n"],"metadata":{"id":"rkZ90rNcTVU_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, num_hiddens, num_heads, dropout, bias=False, **kwargs):\n","        super().__init__()\n","        self.num_heads = num_heads\n","        self.attention = DotProductAttention(dropout)\n","        self.W_q = nn.LazyLinear(num_hiddens, bias=bias)\n","        self.W_k = nn.LazyLinear(num_hiddens, bias=bias)\n","        self.W_v = nn.LazyLinear(num_hiddens, bias=bias)\n","        self.W_o = nn.LazyLinear(num_hiddens, bias=bias)\n","    def forward(self, queries, keys, values, valid_lens):\n","        queries = self.transpose_qkv(self.W_q(queries))\n","        keys = self.transpose_qkv(self.W_k(keys))\n","        values = self.transpose_qkv(self.W_v(values))\n","        if valid_lens is not None:\n","            valid_lens = torch.repeat_interleave(\n","                valid_lens, repeats=self.num_heads, dim=0)\n","        output = self.attention(queries, keys, values, valid_lens)\n","        output_concat = self.transpose_output(output)\n","        return self.W_o(output_concat)\n","    def transpose_qkv(self, X):\n","        X = X.reshape(X.shape[0], X.shape[1], self.num_heads, -1)\n","        X = X.permute(0, 2, 1, 3)\n","        return X.reshape(-1, X.shape[2], X.shape[3])\n","    def transpose_output(self, X):\n","        X = X.reshape(-1, self.num_heads, X.shape[1], X.shape[2])\n","        X = X.permute(0, 2, 1, 3)\n","        return X.reshape(X.shape[0], X.shape[1], -1)\n",""],"metadata":{"id":"k-ro4D0WT1xt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_step(self, batch, device, num_steps,save_attention_weights=False):\n","  batch = [a.to(device) for a in batch]\n","  src, tgt, src_valid_len, _ = batch\n","  enc_all_outputs = self.encoder(src, src_valid_len)\n","  dec_state = self.decoder.init_state(enc_all_outputs, src_valid_len)\n","  outputs, attention_weights = [tgt[:, (0)].unsqueeze(1), ], []\n","  for _ in range(num_steps):\n","    Y, dec_state = self.decoder(outputs[-1], dec_state)\n","    outputs.append(Y.argmax(2))\n","    if save_attention_weights:\n","      attention_weights.append(self.decoder.attention_weights)\n","  return torch.cat(outputs[1:], 1), attention_weights"],"metadata":{"id":"81262E8NBxSV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math"],"metadata":{"id":"g0mx5GniClS4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def bleu(pred_seq, label_seq, k):\n","  pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n","  len_pred, len_label = len(pred_tokens), len(label_tokens)\n","  score = math.exp(min(0, 1 - len_label / len_pred))\n","  for n in range(1, min(k, len_pred)+1):\n","    num_matches, label_subs = 0, collections.defaultdict(int)\n","    for i in range(len_label - n + 1):\n","      label_subs[''.join(label_tokens[i: i +n])] += 1\n","    for i in range(len_pred - n + 1):\n","      if label_subs[''.join(pred_tokens[i: i + n])] > 0:\n","        num_matches += 1\n","        label_subs[''.join(pred_tokens[i: i + n])] -= 1\n","    score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n","  return score"],"metadata":{"id":"z8KwYqPPCR0b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cpu():\n","  \"\"\"Get the CPU device.\"\"\"\n","  return torch.device('cpu')\n","def try_gpu(i=0):\n","  if num_gpus() >= i + 1:\n","    return gpu(i)\n","  return cpu()"],"metadata":{"id":"A0rlJZjJDSsD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["engs = ['go .', 'i lost .', 'he\\'s calm .', 'i\\'m home .']\n","fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n","preds, _ = model.predict_step(data.build(engs, fras), try_gpu(), data.num_steps)\n","for en, fr, p in zip(engs, fras, preds):\n","  translation = []\n","  for token in data.tgt_vocab.to_tokens(p):\n","    if token == '<eos>':\n","      break\n","    translation.append(token)\n","  print(f'{en} => {translation}, bleu,'f'{bleu(\" \".join(translation), fr, k=2):.3f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HqTcRj05DZko","executionInfo":{"status":"ok","timestamp":1749905083616,"user_tz":-420,"elapsed":13,"user":{"displayName":"K61 NGUYỄN KHÁNH HUYỀN","userId":"14018202072431551609"}},"outputId":"f2a898ef-6fb9-485b-bcac-a60d0904c848"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["go . => ['<unk>', '!<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], bleu,0.000\n","i lost . => [\"j'ai\", '<unk>'], bleu,0.000\n","he's calm . => ['je', 'suis', '<unk>'], bleu,0.000\n","i'm home . => ['je', 'suis', '<unk>'], bleu,0.353\n"]}]}]}